通過一個convolution，它變成一張新的圖片，有64個channel。這個convolution layer當然可以疊很多層，剛才疊了第一層。如果疊第二層會發生什麼事呢？第二層的convolution裡面也有一堆filter。每一個filter的大小，我們這邊也設3乘以3。它的高度必須設為64。為什麼？我們知道filter的高度，就是它要處理的影像的channel。所以剛才第一層的convolution，假設輸入的影像是黑白的，channel是1，那filter的高度就是1。輸入的影像如果是彩色的，channel是3，那filter的高度就是3。在第二層裡面，我們也會得到一張影像。對第二個convolution layer來說，它的輸入也是一張圖片。這個圖片的channel是多少？這個圖片的channel是64。這64怎麼來？這個64是前一個convolution layer的filter數目。前一個convolution layer filter數目64，輸出以後就是64個channel。所以第二層，假設你想要把這個圖片當作輸入，那filter的高度也得是64。所以第二層也有一把filter，只是這把filter的高度是64。接下來要回答一個問題就是，如果filter的大小一直設3乘以3，會不會讓network沒有辦法看比較大範圍的pattern呢？其實不會。因為你想想看，如果我們在第二層convolution layer，filter的大小一樣設3乘以3的話，會發生什麼事情呢？如果一樣設3乘以3的話，當我們看最左上角這個數值的時候，最左上角這個數值在影像上是對應到這個範圍。右下角的數值，在影像上是對應到這個範圍。所以當我們看這3乘以3的範圍的時候，看第一個convolution layer輸出的feature map的3乘以3的範圍的時候，我們在原來的影像上是考慮了一個5乘以5的範圍。所以雖然filter只有3乘3，但它在影像上考慮的範圍比較大，是5乘5。所以今天network疊得越深，同樣是3乘以3大小的filter，它看的範圍就會越來越大。所以network夠深，不用怕偵測不到比較大的pattern，它還是可以偵測到比較大的pattern。剛才我們講了兩個版本的故事。這兩個版本的故事一模一樣。我們在第一個版本故事裡面說到，有些neuron會共用參數。這些共用的參數就是第二個版本故事裡面的filter。這組參數有3乘以3乘以3個，這個filter裡面有3乘以3乘以3個數值。我特別用顏色把這些數字圈起來告訴你，這個weight就是這個數字，這個weight就是這個數字，這個weight可能就是這個數字，以此類推。這邊我把bias去掉了，neuron是有bias的。filter有沒有bias呢？其實有，只是在剛才的故事裡面沒有提到。在一般的實作上，CNN的filter都還是有bias的數值。在剛才第一個版本的故事裡面，我們說，不同neuron可以share weight，去守備不同範圍。Share weight這件事，就是我們把filter掃過一張圖片。把filter掃過一張圖片這件事，就是convolution。這就是為什麼convolution layer要叫convolution layer的關係。因為把filter掃過一張圖片這件事情就是convolution。所謂把filter掃過圖片這件事情，就是不同receptive field的neuron可以共用參數。而這組共用的參數就叫做一個filter。我們今天特別從兩個不同面向跟你講CNN這個東西。希望可以幫助你對CNN有更深的了解。所以我們說，為什麼用CNN是基於兩個觀察。第一個觀察是我們不需要看整張圖片。對neuron的故事版本，對第一個故事而言就是，neuron看圖片的一小部分。對filter的故事而言就是，我們有一組filter，每個filter只看小範圍，只偵測小的pattern。我們說，同樣的pattern可能出現在圖片不同地方。所以neuron間可以共用參數。對filter的故事而言就是，filter要掃過整張圖片。這就是convolution layer。Convolution layer在做影像辨識的時候，還有第三個常用的東西。這個東西叫做pooling。Pooling怎麼來的？pooling來自於另一個觀察。這個觀察是，我們把一張較大的圖片做sampling。