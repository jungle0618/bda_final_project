convolutional layer 在做影像辨識的時候呢,其實還有第三個常用的東西,這個東西呢,叫做pooling。那pooling是怎麼來的呢？pooling來自於另外一個觀察，這個觀察是我們把一張比較大的圖片做subsampling。舉例來說，你把偶數的column都拿掉，基數的row都拿掉，圖片變為原來的四分之一，但是不會影響裡面是什麼東西。把一張大的圖片縮小，這是一隻鳥，這張小圖片，你看起來還是一隻鳥。 喔那所以呢，有了pooling這樣的設計，那pooling是怎麼運作的呢？pooling這個東西啊，它本身沒有參數，所以它不是一個layer，它裡面沒有weight，它沒有要認的東西。所以有人會告訴你說pooling呢比較像是一個activation function，比較像是sigmoid啊、ReLU那些，因為它裡面是沒有要認的東西，它就是一個operator，它的行為都是固定好的，沒有要根據data學任何東西。 那pooling其實也有很多不同的版本啦，我們這邊講的是max pooling。好，max pooling是怎麼運作的呢？我們剛才說每一個filter都產生一把數字，每一個filter都產生一把數字。要做pooling的時候，我們就把這些數字幾個幾個一組，比如說在這個例子裡面就是二乘二個一組，二乘二個一組，二乘二個一組。每一組裡面選一個代表。在max pooling裡面，我們選的代表就是最大的那一個。 那你可能會問說為什麼是選最大的那一個呢？你不一定要選最大的那一個，這個是你自己可以決定的。max pooling這一個方法是選最大的那一個，但是也有min pooling啊，min pooling就是選平均嘛。我還看過選幾何平均的，所以有各式各樣的pooling的方法。那你說這邊一定要二乘以二個一組嗎？也不一定，這個也是你自己決定的。你要三乘以三、四乘以四，也可以，這個是你自己決定的。 好，所以我們做完convolution以後，往往後面呢還會搭配pooling。那pooling做的事情就是把圖片變小。做完convolution以後我們會得到一張圖片，這張圖片裡面有很多的channel。那做完pooling以後我們就是把這張圖片的channel不變，本來64個channel還是64個channel，但是我們會把圖片變得比較小張一點。在剛才的例子裡面，本來四乘以四的圖片，如果我們把這個這個這個output的數值啊，二乘以二個一組的話，那四乘以四的圖片就會變成二乘以二的圖片，那這個就是pooling所做的事情。 那一般在實作上啊，往往就是convolution跟pooling交替使用。就是你可能做幾次convolution，做一次pooling。比如兩次convolution一次pooling，兩次convolution一次pooling。 不過你可以想見說pooling對於你的performance還是可能會帶來一點傷害的，因為假設你今天要偵測的是非常微細的東西，那你隨便做subsampling performance可能會稍微差一點。所以近年來你會發現很多影像辨識的network的設計，往往也開始把pooling丟掉，它會做這種全convolution的neural network，就整個network裡面通通都是convolution，完全都不用pooling。那這是因為近年來運算能力越來越強，pooling最主要的理由是為了減少運算量，做subsampling，把影像變少、小，減少運算量。那如果你今天你的運算資源足夠支撐你，不做pooling的話，很多network的架構的設計，往往今天就不做pooling，全convolution，convolution從頭到尾，然後看看做不做的起來，看看能不能夠做得更好。 好，那一般你的架構就是convolution加pooling。那我剛才講過說pooling是可有可無啦，今天很多人可能會選擇不用pooling。 好，那如果你做完幾次convolution以後，接下來呢，最終怎麼得到最後的結果呢？你會把pooling的output做一件事情叫做flatten。flatten這個字眼剛才在作業二裡面助教其實也有提到，所謂flatten的意思就是把這個影像裡面啊，本來排成矩陣的樣子的東西拉直，把所有的數值拉直變成一個向量。再把這個向量丟進fully connected的layer裡面。最終你可能還要過個softmax，然後最終得到影像辨識的結果。這就是一個經典的影像辨識的network，它可能有的樣子。就是長這樣，裡面有convolution、有pooling、有flatten，最後再通過幾個fully connected的layer，過softmax，最終得到影像辨識的結果。那我們在作業三就是會做一個影像辨識的題目。 好，那除了影像辨識以外啊，你可能聽過CNN另外一個最常見的、最耳熟能詳的應用，就是用來下圍棋。那今天呢，如果講個機器學習的課沒有提到AlphaGo，大家就覺得你什麼都沒講對不對，所以我們來提一下AlphaGo。 好，怎麼用這個CNN來下圍棋呢？我們說下圍棋其實就是一個分類的問題。 啊，你的network的輸入是棋盤上黑子跟白子的位置。你的輸出