在這個地方。你就會按照這個方式掃過整張圖片。所以整張圖片裡面每一寸土地都是有被某一個 receptive field 覆蓋的。也就是圖片裡面每一個位置都有一群 neuron 在偵測那個地方有沒有出現某些 pattern。這個是第一個簡化 fully connected network 的方式。第二個觀察是什麼呢？第二個觀察是同樣的 pattern 它可能會出現在圖片的不同區域裡面。比如說鳥嘴這個 pattern，它可能出現在圖片的左上角，也可能出現在圖片的中間。雖然它們的形狀都是一樣的，都是鳥嘴，但是它們可能出現在圖片裡面的不同的位置。但在我們，按照我們剛才的討論，以同樣的 pattern 出現在圖片的不同的位置似乎也不是太大的問題，因為出現在左上角的鳥嘴，它一定落在某一個 receptive field 裡面，因為 receptive field 是蓋滿整個圖片的，所以圖片裡面沒有任何地方不是在某個 neuron 的守備範圍內，所以這個地方一定是某一個 neuron 的 receptive field。那假設在那個 receptive field 裡面有一個 neuron，它的工作是偵測鳥嘴的話，那鳥嘴就會被偵測出來。所以就算鳥嘴出現在中間也沒有關係。假設有，這邊一定是在某一個 receptive field 的範圍裡面。那個 receptive field 一定有一組 neuron 在照護。那假設其中有一個 neuron，它可以偵測鳥嘴的話，那鳥嘴出現在圖片的中間也會被偵測出來。但這邊的問題是，這些偵測鳥嘴的 neuron，它們做的事情其實是一樣的，只是它們守備的範圍是不一樣的。那既然它們做的事情是一樣的，守備範圍是不一樣的，我們真的需要每一個守備範圍都去放一個偵測鳥嘴的 neuron 嗎？它們做的事情根本是重複的，只是它們的守備範圍不一樣。如果不同守備範圍都要有一個偵測鳥嘴的 neuron，那你的參數量不會太多了嗎？這個概念就好像為什麼教務處希望可以推大型的課程一樣。假設每一個科系其實都需要程式相關的課程，或每一個科系都需要機器學習相關的課程，那到底需不需要在每一個系所都開機器學習的課程，還是開一個比較大班的課程，讓所有系所的人都可以修課。這是教務處推動大型課程的想法。那如果放在影像處理上的話，是怎麼樣呢？如果放在影像處理上的話，我們能不能夠讓不同 receptive field 的 neuron，它們共享參數，也就是做 parameter sharing，共享參數。那共享參數是什麼意思呢？這邊舉的更具體一點。所謂共享參數是這兩個 neuron，它們的 weight 完全是一樣的。我這邊特別用顏色來告訴你，它們的 weight 完全是一樣的。上面這個 neuron 的第一個 weight 叫做 W1，下面這個 neuron 的第一個 weight 也是 W1。它們是同一個 weight，我們都用黃色來表示。上面這個 neuron 的第二個 weight 是 W2，下面這個 neuron 的第二個 weight 也是 W2。它們都用黃色來表示。以此類推。上面這個 neuron 跟下面這個 neuron，它們守備的 receptive field 是不一樣的，但是它們的參數是一模一樣的。那有人可能會問，它的參數是一模一樣，那它會不會輸出永遠都是一樣的？不會。為什麼？因為它們的輸入是不一樣的。這兩個 neuron 的參數一模一樣，但是它們照顧的範圍是不一樣的。所以上面這個 neuron，我們說它的輸入是 X1、X2。下面這個 neuron，我們說它的輸入是 X1 prime、X2 prime。那它們的輸出是什麼呢？上面這個 neuron 的輸出是 X1 乘 W1 加 X2 乘 W2，全部相加再加 bias，然後通過 activation function 得到輸出。下面這個 neuron 雖然也有 W1、W2，但 W1 跟 W2 是乘以 X1 prime、X2 prime。所以它的輸出不會跟上面這個 neuron 一樣。因為輸入不一樣的關係，所以就算是兩個 neuron 共用參數，它們的輸出也不會是一樣的。但你可以想見，你不會讓兩個守備一模一樣 receptive field 的 neuron 共享參數，因為如果今天兩個守備一樣的區域的 neuron 共享參數的話，它們的輸出就一定會是一樣的。但如果兩個 neuron 守備的範圍不一樣，就算它們參數一樣，它們的輸出也不會是一樣的。所以這是第二個簡化。我們讓一些 neuron 可以共享參數。那至於要怎麼共享，你完全可以自己決定。這個是你自己可以決定的事情。但是接下來還是要告訴大家常見的影像辨識上共享的方法是怎麼設定的。那剛才已經講，每一個 receptive field，它都有一組 neuron 在負責守備。比如說