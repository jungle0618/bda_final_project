裡面有100乘100乘三個數字，所以一張圖片是由100乘100乘三個數字所組成的。把這些數字通通拿出來排成一排就是一個巨大的向量，這個向量可以作為network的輸入。而這個向量裡面每一維存的數值就是某一個pixel某一個顏色的強度。每一個pixel有RGB三個顏色所組成，每一個顏色都有一個數值代表這個顏色的強度，在這個向量裡面每一維的數值就代表了某一個位置的某一個顏色的強度。這個向量可以當作network的輸入，我們到目前為止只講過了fully connected的network。如果我們把這個向量當作network的輸入，input這個feature vector的長度就是100乘100乘3，非常長的一個vector。

假設我們現在的第一層neuron數目有1000個，你能計算一下第一層總共有多少個weight嗎？每一個neuron跟輸入向量的每一個數值都會有一個weight。所以如果輸入向量長度是100乘100乘3，有1000個neuron，我們現在第一層的weight就有1000乘100乘100乘3，也就是3乘10的七次方，是個非常巨大的數目。

如果參數越多，會有什麼樣的問題呢？雖然隨著參數的增加，我們可以增加模型的彈性，增加它的能力，但是我們也增加了overfitting的風險。有關什麼叫模型的彈性，到底overfitting是怎麼產生的，下週吳佩遠老師會從數學上給大家清楚的證明，我們這邊就講概念上，如果模型的彈性越大，就越容易overfitting。我們怎麼減少在做影像辨識的時候，怎麼避免使用這麼多的參數呢？

考慮到影像辨識這個問題本身的特性，我們並不一定需要fully connected。考慮影像本身的特性，我們不需要每一個neuron跟input的每一個dimension都有一個weight。接下來是對影像辨識這個問題，影像本身的特性的一些觀察。

第一個觀察：對影像辨識這個問題而言，假設我們想要知道這張圖片裡面有一隻動物，這隻動物是一隻鳥，要怎麼做呢？也許對一個影像辨識系統而言，對一個影像辨識neuron，對一個影像辨識類神經網路裡面的神經元而言，它要做的就是偵測現在這張圖片裡面有沒有出現一些特別重要的pattern，而這些pattern代表了某種物件。舉例來說，如果現在有某個neuron看到鳥嘴這個pattern，某個neuron看到眼睛這個pattern，某個neuron看到鳥爪這個pattern，也許看到這些pattern綜合起來，就代表我們看到了一隻鳥。類神經網路就可以告訴你因為看到這些pattern，所以它看到了一隻鳥。

也許你會覺得看pattern然後決定它是什麼，這事好像沒有很聰明，你就仔細想想，人是不是也是用同樣的方法來看一張圖片中有沒有一隻鳥呢？舉例來說這個例子。你不知道你有沒有看到這裡面有什麼樣的動物，你看這邊有一個鳥嘴，這邊有一個眼睛，看起來它是一隻烏鴉，但它其實是一隻貓。如果你看它是一隻鳥的話，你應該放下酒杯了，因為這是一隻貓。所以就算是人，我們在判斷一個物件的時候，往往也是抓最重要的特徵，看到這些特徵以後，你很直覺就會覺得看到了某種物件。對機器來說，也許這也是一個有效的判斷影像中有什麼物件的方法。

但是假設我們現在要neuron做的事情就是判斷現在有沒有某種pattern出現，也許我們並不需要每一個neuron都去看一張完整的圖片。因為這些重要的pattern，比如說鳥嘴、眼睛、鳥爪，並不需要看整張完整的圖片才能夠得到這些資訊。要知道這邊有沒有一個鳥嘴，你只要看非常小的範圍就知道了，你並不需要看整張圖片。所以這些neuron也許就不需要把整張圖片當作輸入，它們只需要把圖片的一小部分當作輸入，就足以讓它們偵測某些特別關鍵的pattern有沒有出現。這是第一個觀察。

根據這個觀察，我們就可以做第一個簡化。本來我們每一個neuron要看完整的圖片。