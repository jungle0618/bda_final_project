如果講個機器學習的課,沒有提到阿發Go大家就覺得你什麼都沒有講,對不對?所以我們來提一下阿發Go。 好,怎麼用這個CNN來下圍棋呢?我們說下圍棋其實就是一個分類的問題。 那你的network的輸入是棋盤上黑子跟白子的位置。 你的輸出就是下一步應該要落子的位置。 可是我們今天已經知道說network的輸入就是一個向量啊, 那怎麼把棋盤表示成一個向量呢?完全沒有問題。 棋盤上就是有19乘19個位置嘛, 那我們就把一個棋盤表示成一個19乘19為的向量。 在這個向量裡面,如果某一個位置, 有一個黑子,那那個位置我們就填一。 如果有白子,我們就填負一,如果沒有子,我們就填零,那我們就可以告訴network說,我們就可以告訴network說現在棋盤上的盤式長什麼樣子。我們可以用一個19乘19為的向量來描述一個棋盤。當然這不一定是要這麼做了，不一定要黑子是1白子是負1，然後沒有子就是0，這只是一個可能的表示方式而已，你可以想出其他更神奇的表示方式。 總之我們有辦法把棋盤上的盤式用一個向量來描述。把這個向量輸到一個network裡面，然後呢，你就可以把下圍棋當作一個分類的問題，叫這個network去預測下一步應該落子的位置落在哪裡最好。 所以下圍棋就是一個有19乘19個類別的分類的問題。 network會output說在這19乘19個類別裡面哪一個類別是最好的，應該要選擇下一步落子的位置應該在哪裡。 那這個問題完全可以用一個fully connected的network來解決， 但是用CNN的效果更好。 為什麼用CNN的效果更好呢？ 首先你完全可以把一個棋盤看作是一張圖片。 一個棋盤可以看作是一個解析度19乘19的圖片。那一般圖片很大，一般圖片可能都100乘100的解析度都是很小的圖片啦，但是棋盤是一個更小的圖片，這個圖片它的解析度只有19乘19。這個圖片裡面每一個像素，每一個pixel，就代表棋盤上一個可以落子的位置。 那channel呢？ 一般圖片的channel就是RGB嘛，RGB代表一個顏色。那棋盤上每一個pixel的channel應該是什麼呢？ 在阿發Go的原始論文裡面它告訴你說， 每一個棋盤的位置，每一個棋盤上的pixel，它是用48個channel來描述。 也就是說棋盤上的每一個位置，它都用48個數字來描述那個位置發生了什麼事。那至於為什麼是這48個，那這個顯然是圍棋高手設計出來的。那48個位置包括，比如說啊這個位置是不是要被叫吃了，那這個位置旁邊有沒有顏色不一樣的子等等，就是這樣子描述每一個位置，所以你會用48個數字來描述棋盤上的一個位置。 所以一個棋盤它就是19乘19的解析度的圖片，它的channel就是48。 好，但是為什麼CNN可以用在下圍棋上呢？我們剛才就強調說CNN啊，其實並不是你隨便用都會好的，它是為影像設計的，所以如果一個問題它跟影像沒有什麼共同的特性的話，你其實不該用CNN。所以今天既然在下圍棋可以用CNN，那意味著什麼？那意味著圍棋跟影像有共同的特性。 什麼樣共同的特性呢？ 我們剛才講說在影像上的第一個觀察是很多重要的pattern，你只需要看小範圍就知道了。 下圍棋是不是也是一樣呢？ 舉例來說，這個pattern， 你你就算不用看整個棋盤的盤式，你都知道說這邊發生了什麼事。這個就是白子被黑子圍住了嘛，那接下來黑子如果放在這邊，就可以把白子提走，那白子要放在這邊才不會才可以接，這個白子才不會被提走這樣。 那其實在阿發Go裡面啊，它的第一層的layer，它的filter的大小就是5乘5。 所以顯然在設計這個network的人覺得說棋盤上很多重要的pattern也許看5乘5的範圍就可以知道了。 再來是我們說影像上的第二個觀察是同樣的pattern可能會出現在不同的位置。 在下圍棋裡面是不是也是一樣呢？這個叫吃的pattern，它可以出現在棋盤上的任何位置，它可以出現在左上角，也可以出現在右下角。所以從這個觀點來看，影像跟下圍棋有很多共通之處。 但是讓人想不透的地方是，在做影像的時候，我們說我們都會做pooling。也就是一張影像做subsampling以後，並不會影響我們對影像中物件的判讀。 但是棋盤是這個樣子嗎？ 你可以把棋盤上的基數行跟偶數列拿掉，還是同一個棋局嗎？ 聽起來好像不是對不對？下圍棋這麼精細的任務你隨便拿掉一個column，拿掉一個row，整個整個局勢就不一樣啦，怎麼可能拿掉一個row