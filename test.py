import os
import time
import math  # å¼•å…¥ math æ¨¡çµ„
from typing import Annotated, List, Dict, Any
from typing_extensions import TypedDict
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
# from langchain_google_genai import ChatGoogleGenerativeAI # é€™å€‹è®Šæ•¸æœªä½¿ç”¨ï¼Œå¯ä»¥åˆªé™¤
from google import genai
from pydub import AudioSegment
from multiprocessing import Pool, cpu_count
from functools import partial
import threading
from collections import deque

# --- å®‰å…¨æ€§ä¿®æ­£ï¼šå¾ç’°å¢ƒè®Šæ•¸è®€å– API é‡‘é‘° ---
# åŸ·è¡Œå‰ï¼Œè«‹åœ¨ä½ çš„çµ‚ç«¯æ©Ÿè¨­å®šç’°å¢ƒè®Šæ•¸ï¼š
# export GOOGLE_API_KEY="ä½ çš„AIzaSy...é‡‘é‘°"
api_key = os.environ.get("GEMINI_API_KEY")
if not api_key:
    raise ValueError("GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®šã€‚")

# ----------------------------------------

pwd = os.getcwd()

class AllState(TypedDict):
    messages: Annotated[list, add_messages]
    raw_audio_path: str
    workspace_path: str
    file_name: str
    # --- æ–°å¢ ---
    slice_summaries: List[str] # ç”¨æ–¼ Map éšæ®µçš„è¼¸å‡º
    final_summary: str         # ç”¨æ–¼ Reduce éšæ®µçš„è¼¸å‡º

# llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", api_key=api_key) # æœªä½¿ç”¨ï¼Œå·²è¨»è§£

class RateLimiter:
    """é€Ÿç‡é™åˆ¶å™¨ï¼Œç¢ºä¿ä¸è¶…é Gemini API çš„é™åˆ¶"""
    
    def __init__(self, max_requests_per_minute=1800):  # å…è²»æ–¹æ¡ˆï¼šä¿å®ˆè¨­å®šï¼Œä½æ–¼ 2000 RPM é™åˆ¶
        self.max_requests_per_minute = max_requests_per_minute
        self.requests = deque()
        self.lock = threading.Lock()
        print(f"ğŸš¦ é€Ÿç‡é™åˆ¶å™¨åˆå§‹åŒ–ï¼šæ¯åˆ†é˜æœ€å¤š {max_requests_per_minute} å€‹è«‹æ±‚")
    
    def wait_if_needed(self):
        """å¦‚æœéœ€è¦ï¼Œç­‰å¾…ç›´åˆ°å¯ä»¥ç™¼é€ä¸‹ä¸€å€‹è«‹æ±‚"""
        with self.lock:
            now = time.time()
            # ç§»é™¤ä¸€åˆ†é˜å‰çš„è«‹æ±‚è¨˜éŒ„
            while self.requests and now - self.requests[0] > 60:
                self.requests.popleft()
            
            # å¦‚æœé”åˆ°é™åˆ¶ï¼Œç­‰å¾…
            if len(self.requests) >= self.max_requests_per_minute:
                sleep_time = 60 - (now - self.requests[0])
                if sleep_time > 0:
                    print(f"â³ é€Ÿç‡é™åˆ¶ï¼šç­‰å¾… {sleep_time:.1f} ç§’...")
                    time.sleep(sleep_time)
                    # é‡æ–°è¨ˆç®—
                    now = time.time()
                    while self.requests and now - self.requests[0] > 60:
                        self.requests.popleft()
            
            # è¨˜éŒ„é€™å€‹è«‹æ±‚
            self.requests.append(now)

# å…¨åŸŸé€Ÿç‡é™åˆ¶å™¨
rate_limiter = RateLimiter()

def create_dir(state: AllState):  # å»ºç«‹å·¥ä½œç›®éŒ„
    file_name = state["file_name"]
    # ä½¿ç”¨ os.path.join ç¢ºä¿è·¯å¾‘ç›¸å®¹æ€§
    workspace_path = os.path.join(pwd, "workspace", file_name)
    raw_audio_path = os.path.join(pwd, "audio", file_name)

    os.makedirs(workspace_path, exist_ok=True)
    state["workspace_path"] = workspace_path
    state["raw_audio_path"] = raw_audio_path

    os.makedirs(os.path.join(workspace_path, "slice_audio"), exist_ok=True)
    os.makedirs(os.path.join(workspace_path, "transcript"), exist_ok=True)
    os.makedirs(os.path.join(workspace_path, "transcript_simplified"), exist_ok=True)
    print(f"ğŸ“ ç›®éŒ„å·²å»ºç«‹: {workspace_path}")
    return state

def slice_audio(state: AllState):  # æŠŠmp3åˆ‡ç‰‡
    segment_length = 5 * 60 * 1000  # 5 minutes in milliseconds
    overlap_length = 20 * 1000      # 20 seconds in milliseconds

    file_path = state["raw_audio_path"]
    workspace_path = state["workspace_path"]
    slice_dir = os.path.join(workspace_path, "slice_audio")

    print(f"ğŸ”ª æ­£åœ¨è®€å–éŸ³æª”: {file_path}")
    # ä¿®æ­£ï¼šä½¿ç”¨ from_file æ›´æœ‰å½ˆæ€§
    try:
        audio = AudioSegment.from_file(file_path)
    except Exception as e:
        print(f"Error loading audio file {file_path}: {e}")
        # å¦‚æœéŸ³æª”è¼‰å…¥å¤±æ•—ï¼Œæˆ‘å€‘æ‡‰è©²åœæ­¢æµç¨‹ï¼Œå¯ä»¥æ‹‹å‡ºç•°å¸¸
        raise
        
    if len(audio) == 0:
        print("âš ï¸ è­¦å‘Šï¼šéŸ³æª”é•·åº¦ç‚º 0ï¼Œå°‡ä¸é€²è¡Œåˆ‡ç‰‡ã€‚")
        return state

    

    # ä¿®æ­£ï¼šä½¿ç”¨ math.ceil ç¢ºä¿è¨ˆç®—æ­£ç¢º
    num_segments = math.ceil(len(audio) / segment_length)
    print(f"ğŸ”ª éŸ³æª”ç¸½é•·åº¦: {len(audio) / 1000:.2f} ç§’ï¼Œå°‡åˆ‡åˆ†ç‚º {num_segments} å€‹ç‰‡æ®µã€‚")

    for i in range(num_segments):
        start = i * segment_length
        end = min(start + segment_length + overlap_length, len(audio))
        segment = audio[start:end]
        output_path = os.path.join(slice_dir, f"part_{i}.mp3")
        segment.export(output_path, format="mp3")
        
    print(f"ğŸ”ª åˆ‡ç‰‡å®Œæˆï¼Œå·²å„²å­˜è‡³ {slice_dir}")
    return state

def process_single_slice(args: tuple) -> Dict[str, Any]:
    """
    Map function: è™•ç†å–®å€‹éŸ³é »åˆ‡ç‰‡
    è¼¸å…¥: (slice_file_path, workspace_path, api_key)
    è¼¸å‡º: {slice_name, transcript, cleaned_text, summary}
    """
    slice_file_path, workspace_path, api_key = args
    
    # åˆå§‹åŒ–å®¢æˆ¶ç«¯
    audio_client = genai.Client(api_key=api_key)
    
    slice_name = os.path.basename(slice_file_path)
    print(f"  > æ­£åœ¨è™•ç† {slice_name}...")
    
    result = {
        'slice_name': slice_name,
        'transcript': '',
        'cleaned_text': '',
        'summary': '',
        'error': None
    }
    
    try:
        # 1. ä¸Šå‚³ä¸¦è½‰éŒ„
        myfile = audio_client.files.upload(file=slice_file_path)
        
        # ç­‰å¾…ä¸Šå‚³å®Œæˆ
        max_retries = 60
        for _ in range(max_retries):
            myfile = audio_client.files.get(name=myfile.name)
            if myfile.state == "ACTIVE":
                break
            time.sleep(1)
        
        if myfile.state != "ACTIVE":
            result['error'] = f"æª”æ¡ˆä¸Šå‚³å¤±æ•—ï¼Œç‹€æ…‹: {myfile.state}"
            return result
        
        # è½‰éŒ„ - æ·»åŠ é€Ÿç‡é™åˆ¶
        rate_limiter.wait_if_needed()
        prompt = 'Generate a transcript of the speech.'
        response = audio_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=[prompt, myfile]
        )
        result['transcript'] = response.text
        
        # 2. æ¸…ç†æ–‡æœ¬
        if result['transcript'].strip():
            # æ·»åŠ é€Ÿç‡é™åˆ¶
            rate_limiter.wait_if_needed()
            clean_prompt = f"""
            è«‹ä½ æ‰®æ¼”ä¸€å€‹é€å­—ç¨¿ç·¨è¼¯ã€‚
            ä»»å‹™ï¼šæ¸…ç†ä»¥ä¸‹çš„èªéŸ³è½‰éŒ„ç¨¿ã€‚
            è¦å‰‡ï¼š
            1. åˆªé™¤æ‰€æœ‰è´…å­—å’Œå¡«å……è© (ä¾‹å¦‚ "å—¯", "å•Š", "é‚£å€‹", "å°±æ˜¯", "ä½ çŸ¥é“å—", "like", "um", "ah" ç­‰)ã€‚
            2. åˆªé™¤å£åƒæˆ–é‡è¤‡çš„è©èªã€‚
            3. ä¿®æ­£æ˜é¡¯çš„æ‹¼å¯«æˆ–æ–‡æ³•éŒ¯èª¤ã€‚
            4. **ä¸è¦ç¸½çµ**ã€‚ä¿ç•™åŸå§‹çš„èªå¥çµæ§‹å’Œæ‰€æœ‰æ ¸å¿ƒè³‡è¨Šã€‚
            5. **åƒ…è¼¸å‡º**æ¸…ç†å¾Œçš„æ–‡å­—ã€‚

            åŸå§‹è½‰éŒ„ç¨¿ï¼š
            ---
            {result['transcript']}
            ---
            æ¸…ç†å¾Œçš„è½‰éŒ„ç¨¿ï¼š
            """
            
            clean_response = audio_client.models.generate_content(
                model='gemini-2.5-flash',
                contents=[clean_prompt]
            )
            result['cleaned_text'] = clean_response.text
        else:
            result['cleaned_text'] = ""
        
        # 3. ç”Ÿæˆæ‘˜è¦
        if result['cleaned_text'].strip():
            # æ·»åŠ é€Ÿç‡é™åˆ¶
            rate_limiter.wait_if_needed()
            summary_prompt = f"""
            è«‹ç‚ºä»¥ä¸‹æ–‡æœ¬ç”Ÿæˆä¸€å€‹ç°¡æ½”çš„æ‘˜è¦ï¼ŒåŒ…å«ï¼š
            1. ä¸»è¦å…§å®¹æ¦‚è¿°
            2. é—œéµè¦é»ï¼ˆ3-5å€‹ï¼‰
            3. é‡è¦æ±ºç­–æˆ–çµè«–ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰

            æ–‡æœ¬å…§å®¹ï¼š
            ---
            {result['cleaned_text']}
            ---

            æ‘˜è¦ï¼š
            """
            
            summary_response = audio_client.models.generate_content(
                model='gemini-2.5-flash',
                contents=[summary_prompt]
            )
            result['summary'] = summary_response.text
        else:
            result['summary'] = ""
        
        print(f"  > âœ… {slice_name} è™•ç†å®Œæˆ")
        
    except Exception as e:
        result['error'] = str(e)
        print(f"  > âŒ è™•ç† {slice_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    return result

def map_reduce_process_slices(state: AllState):
    """
    MapReduce ä¸»å‡½æ•¸ï¼šä¸¦è¡Œè™•ç†æ‰€æœ‰éŸ³é »åˆ‡ç‰‡
    """
    workspace_path = state['workspace_path']
    slice_audio_dir = os.path.join(workspace_path, "slice_audio")
    transcript_dir = os.path.join(workspace_path, "transcript")
    simplified_dir = os.path.join(workspace_path, "transcript_simplified")
    summary_dir = os.path.join(workspace_path, "summaries")
    
    # å»ºç«‹å¿…è¦çš„ç›®éŒ„
    os.makedirs(transcript_dir, exist_ok=True)
    os.makedirs(simplified_dir, exist_ok=True)
    os.makedirs(summary_dir, exist_ok=True)
    
    # å–å¾—æ‰€æœ‰åˆ‡ç‰‡æª”æ¡ˆ
    try:
        slice_files = [f for f in os.listdir(slice_audio_dir) if f.endswith('.mp3')]
        slice_files.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))
    except Exception as e:
        print(f"Error reading slice files: {e}")
        return state
    
    if not slice_files:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•éŸ³é »åˆ‡ç‰‡")
        return state
    
    print(f"ğŸ”„ é–‹å§‹ MapReduce è™•ç† {len(slice_files)} å€‹åˆ‡ç‰‡...")
    
    # æº–å‚™ Map å‡½æ•¸çš„åƒæ•¸
    slice_paths = [os.path.join(slice_audio_dir, f) for f in slice_files]
    map_args = [(path, workspace_path, api_key) for path in slice_paths]
    
    # ä½¿ç”¨å¤šé€²ç¨‹ä¸¦è¡Œè™•ç† (Map éšæ®µ) - å…è²»æ–¹æ¡ˆä¿å®ˆè¨­å®š
    # æ¯å€‹é€²ç¨‹æœƒé€²è¡Œ 3 æ¬¡ API èª¿ç”¨ï¼ˆè½‰éŒ„ã€æ¸…ç†ã€æ‘˜è¦ï¼‰ï¼Œæ‰€ä»¥é™åˆ¶é€²ç¨‹æ•¸
    max_concurrent_processes = min(4, cpu_count(), len(slice_files))  # æœ€å¤š 4 å€‹é€²ç¨‹
    num_processes = max_concurrent_processes
    print(f"ğŸš€ å…è²»æ–¹æ¡ˆï¼šä½¿ç”¨ {num_processes} å€‹é€²ç¨‹ä¸¦è¡Œè™•ç†ï¼ˆæœ€å¤š 4 å€‹ï¼‰...")
    print(f"ğŸ“Š é ä¼°æ¯åˆ†é˜ API èª¿ç”¨ï¼š{num_processes * 3} æ¬¡ï¼ˆè½‰éŒ„+æ¸…ç†+æ‘˜è¦ï¼‰")
    
    with Pool(processes=num_processes) as pool:
        print(f"â³ é–‹å§‹è™•ç† {len(slice_files)} å€‹éŸ³é »åˆ‡ç‰‡...")
        results = pool.map(process_single_slice, map_args)
    
    # å„²å­˜çµæœä¸¦æ”¶é›†æ‘˜è¦ (Reduce éšæ®µ)
    all_summaries = []
    
    for result in results:
        slice_name = result['slice_name']
        base_name = slice_name.replace('.mp3', '')
        
        # å„²å­˜è½‰éŒ„ç¨¿
        if result['transcript']:
            transcript_path = os.path.join(transcript_dir, f"{base_name}.txt")
            with open(transcript_path, 'w', encoding='utf-8') as f:
                f.write(result['transcript'])
        
        # å„²å­˜æ¸…ç†å¾Œçš„æ–‡æœ¬
        if result['cleaned_text']:
            simplified_path = os.path.join(simplified_dir, f"{base_name}.txt")
            with open(simplified_path, 'w', encoding='utf-8') as f:
                f.write(result['cleaned_text'])
        
        # å„²å­˜å–®å€‹æ‘˜è¦
        if result['summary']:
            summary_path = os.path.join(summary_dir, f"{base_name}_summary.txt")
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(result['summary'])
            all_summaries.append(result['summary'])
        
        # å ±å‘ŠéŒ¯èª¤
        if result['error']:
            print(f"  > âŒ {slice_name}: {result['error']}")
    
    # å„²å­˜æ‰€æœ‰æ‘˜è¦åˆ° state ä¸­ä¾›å¾ŒçºŒä½¿ç”¨
    state['slice_summaries'] = all_summaries
    
    print(f"ğŸ‰ MapReduce è™•ç†å®Œæˆï¼Œå…±è™•ç† {len(results)} å€‹åˆ‡ç‰‡")
    return state

def reduce_final_summary(state: AllState):
    """
    Reduce å‡½æ•¸ï¼šå°‡æ‰€æœ‰åˆ‡ç‰‡æ‘˜è¦åˆä½µæˆæœ€çµ‚æ‘˜è¦
    """
    if 'slice_summaries' not in state or not state['slice_summaries']:
        print("âš ï¸ æ²’æœ‰æ‰¾åˆ°åˆ‡ç‰‡æ‘˜è¦ï¼Œè·³éæœ€çµ‚æ‘˜è¦ç”Ÿæˆ")
        return state
    
    workspace_path = state['workspace_path']
    summary_dir = os.path.join(workspace_path, "summaries")
    
    print("ğŸ”„ é–‹å§‹ç”Ÿæˆæœ€çµ‚æ‘˜è¦...")
    
    # åˆä½µæ‰€æœ‰æ‘˜è¦
    combined_summaries = "\n\n".join(state['slice_summaries'])
    
    # ç”Ÿæˆæœ€çµ‚æ‘˜è¦
    final_summary_prompt = f"""
    è«‹åŸºæ–¼ä»¥ä¸‹å„å€‹ç‰‡æ®µçš„æ‘˜è¦ï¼Œç”Ÿæˆä¸€å€‹å®Œæ•´çš„ã€çµæ§‹åŒ–çš„æœ€çµ‚æ‘˜è¦ã€‚
    
    è¦æ±‚ï¼š
    1. æä¾›æ•´é«”å…§å®¹çš„ä¸»æ—¨æ¦‚è¿°
    2. æ•´ç†ä¸¦åˆä½µæ‰€æœ‰é—œéµè¦é»ï¼ˆå»é™¤é‡è¤‡ï¼‰
    3. è­˜åˆ¥é‡è¦çš„æ±ºç­–ã€çµè«–æˆ–è¡Œå‹•é …ç›®
    4. ä¿æŒé‚è¼¯é †åºå’Œé€£è²«æ€§
    5. ä½¿ç”¨æ¸…æ™°çš„æ¨™é¡Œå’Œçµæ§‹
    
    å„ç‰‡æ®µæ‘˜è¦ï¼š
    ---
    {combined_summaries}
    ---
    
    æœ€çµ‚æ‘˜è¦ï¼š
    """
    
    try:
        # æ·»åŠ é€Ÿç‡é™åˆ¶
        rate_limiter.wait_if_needed()
        audio_client = genai.Client(api_key=api_key)
        response = audio_client.models.generate_content(
            model='gemini-2.5-flash',
            contents=[final_summary_prompt]
        )
        
        # å„²å­˜æœ€çµ‚æ‘˜è¦
        final_summary_path = os.path.join(summary_dir, "final_summary.txt")
        with open(final_summary_path, 'w', encoding='utf-8') as f:
            f.write(response.text)
        
        state['final_summary'] = response.text
        print("âœ… æœ€çµ‚æ‘˜è¦ç”Ÿæˆå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæœ€çµ‚æ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        state['final_summary'] = "æ‘˜è¦ç”Ÿæˆå¤±æ•—"
    
    return state

# Build the state graph
graph_builder = StateGraph(AllState)
graph_builder.add_node("create_dir", create_dir)
graph_builder.add_node("slice_audio", slice_audio)
graph_builder.add_node("map_reduce_process", map_reduce_process_slices)
graph_builder.add_node("reduce_final_summary", reduce_final_summary)

graph_builder.set_entry_point("create_dir")
graph_builder.add_edge("create_dir", "slice_audio")
graph_builder.add_edge("slice_audio", "map_reduce_process")
graph_builder.add_edge("map_reduce_process", "reduce_final_summary")
graph_builder.set_finish_point("reduce_final_summary")
app = graph_builder.compile()

# main execution
file_name = input("è«‹è¼¸å…¥éŸ³æª”åç¨±ï¼Œä¾‹å¦‚ï¼šcnn.mp3: ")
init_state: AllState = {"messages": [], "file_name": file_name}

# æª¢æŸ¥åˆå§‹éŸ³æª”æ˜¯å¦å­˜åœ¨
initial_audio_path = os.path.join(pwd, "audio", file_name)
if not os.path.exists(initial_audio_path):
    print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°åˆå§‹éŸ³æª” {initial_audio_path}")
    print("è«‹ç¢ºèª 'audio' è³‡æ–™å¤¾å­˜åœ¨ï¼Œä¸” 'cnn.mp3' æª”æ¡ˆåœ¨è£¡é¢ã€‚")
else:
    print(f"ğŸš€ é–‹å§‹åŸ·è¡Œ LangGraph æµç¨‹ for {file_name}...")
    response = app.invoke(init_state)
    print("ğŸ æµç¨‹åŸ·è¡Œå®Œç•¢ã€‚")
    print(f"ğŸ“‚ æœ€çµ‚å·¥ä½œç›®éŒ„: {response['workspace_path']}")