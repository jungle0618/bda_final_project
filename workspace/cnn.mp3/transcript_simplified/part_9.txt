如果講機器學習的課,沒有提到阿發Go大家就覺得你什麼都沒有講。 所以我們來提一下阿發Go。 怎麼用這個CNN來下圍棋? 我們說下圍棋是一個分類的問題。 你的network的輸入是棋盤上黑子跟白子的位置。 你的輸出是下一步應該要落子的位置。 可是我們今天已經知道說network的輸入是一個向量, 怎麼把棋盤表示成一個向量? 完全沒有問題。 棋盤上有19乘19個位置, 我們就把一個棋盤表示成一個19乘19維的向量。 在這個向量裡面,如果某一個位置有一個黑子,那個位置我們就填一。 如果有白子,我們就填負一,如果沒有子,我們就填零,我們就可以告訴network說現在棋盤上的盤式長什麼樣子。我們可以用一個19乘19維的向量來描述一個棋盤。當然這不一定是要這麼做，不一定要黑子是1白子是負1，沒有子是0，這只是一個可能的表示方式，你可以想出其他更神奇的表示方式。 總之我們有辦法把棋盤上的盤式用一個向量來描述。把這個向量輸到一個network裡面，你就可以把下圍棋當作一個分類的問題，叫這個network去預測下一步應該落子的位置。 所以下圍棋是一個有19乘19個類別的分類問題。 network會output在這19乘19個類別裡面哪一個類別是最好的，下一步落子的位置應該在哪裡。 這個問題完全可以用一個fully connected的network來解決， 但是用CNN的效果更好。 為什麼用CNN的效果更好? 首先你完全可以把一個棋盤看作是一張圖片。 一個棋盤可以看作是一個解析度19乘19的圖片。一般圖片很大，一般圖片可能100乘100的解析度都是很小的圖片，但是棋盤是一個更小的圖片，這個圖片的解析度只有19乘19。這個圖片裡面每一個像素，每一個pixel，代表棋盤上一個可以落子的位置。 Channel? 一般圖片的channel是RGB，RGB代表一個顏色。棋盤上每一個pixel的channel應該是什麼? 在阿發Go的原始論文裡面它告訴你，每一個棋盤的位置，每一個棋盤上的pixel，是用48個channel來描述。 也就是棋盤上的每一個位置，都用48個數字來描述那個位置發生了什麼事。至於為什麼是這48個，這個顯然是圍棋高手設計出來的。48個位置包括，比如說這個位置是不是要被叫吃了，這個位置旁邊有沒有顏色不一樣的子等等，這樣子描述每一個位置，所以你會用48個數字來描述棋盤上的一個位置。 所以一個棋盤它是19乘19解析度的圖片，它的channel是48。 但是為什麼CNN可以用在下圍棋上? 我們剛才強調CNN並不是你隨便用都會好，它是為影像設計的，所以如果一個問題它跟影像沒有共同特性的話，你不該用CNN。所以今天既然在下圍棋可以用CNN，這意味著什麼? 這意味著圍棋跟影像有共同的特性。 什麼樣共同的特性? 我們剛才講在影像上的第一個觀察是很多重要的pattern，你只需要看小範圍就知道了。 下圍棋是不是也是一樣? 舉例來說，這個pattern，你就算不用看整個棋盤的盤式，你都知道這邊發生了什麼事。這是白子被黑子圍住了，接下來黑子如果放在這邊，就可以把白子提走，白子要放在這邊才可以接，才不會被提走。 在阿發Go裡面，它的第一層的layer，filter的大小是5乘5。 所以顯然在設計這個network的人覺得棋盤上很多重要的pattern也許看5乘5的範圍就可以知道了。 再來是我們影像上的第二個觀察是同樣的pattern可能會出現在不同的位置。 在下圍棋裡面是不是也是一樣? 這個叫吃的pattern，它可以出現在棋盤上的任何位置，它可以出現在左上角，也可以出現在右下角。所以從這個觀點來看，影像跟下圍棋有很多共通之處。 但是讓人想不透的地方是，在做影像的時候，我們都會做pooling。也就是一張影像做subsampling以後，並不會影響我們對影像中物件的判讀。 但是棋盤是這個樣子嗎？ 你可以把棋盤上的基數行跟偶數列拿掉，還是同一個棋局嗎？ 聽起來好像不是? 下圍棋這麼精細的任務你隨便拿掉一個column，拿掉一個row，整個局勢就不一樣，怎麼可能拿掉一個row